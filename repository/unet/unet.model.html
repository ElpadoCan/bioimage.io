<docs lang="markdown">
# Unet Model

A generic plugin for image-to-image translation with A-net.

## Usage

### Data preparation
Your data should be organized according to the following structure

```
    - train
    - sample1
        - channelA.png
        - channelB.png
        - channelC.png
    - sample2
        - channelA.png
        - channelB.png
        - channelC.png
    - ...
    - valid
    - sample20
        - channelA.png
        - channelB.png
        - channelC.png
    - ...
    - test
    - sample43
        - channelA.png
        - channelC.png
    - sample44
        - channelA.png
        - channelC.png
```
In the above folder structure, `train/valid/test` are three folders, `sample1`...`sample44` are sample folders, within the sample folder, it contains images with different channels.

For the naming, you have to use `train`/`valid`/`test` as the top level folder name, but the sample name can be choose freely.
You can also choose different channel names (e.g. `DAPI`, `C5`), but you need to make it consistent accross all the sample folder.

These channel names will be used as an identifier for the plugin to recognize them, you will be asked to specify them when you `set working directory`.

### Set working directory and parameters

If you have the samples pepared the next step is to `set working directory` to the root folder of your samples.

And you will be asked to specify the identifiers for your plugin.

The following parameter can be configured:
    * input identifiers and output identifiers: a string which specifies the naming pattern of each input and output channels, for example, the above folder structure contains `channelA.png`, `channelB.png` and `channelC.png`,
    if we want to use all the `channelA.png` and `channelC.png` as input channels, we can set `Cells=channelA*.png,DAPI=channelC*.png`,
    where before `=` is the name we given for each channel, and we used `,` to seperate channels. Similary for the input channels, we can specify `Mask=channelB*.png`.

Here we used a `*` here which means it can be replaced with any symbol, here there is no extra, it is designed for when there are multiple images belongs to the same channel.

## Optionally, loading previously trained models

## start the training

The training will relying on two folders named `train` and `valid`, you need to make sure you have them in your working directory.

You can specify a training name, which will be used a prefix for saving models and logs.
Choose the `epochs`, `step per epoch` and `batch size` you want to train.

Then you can start training by click on the plugin menu.

If the training is done, you will get your model located in the `working directory`, the folder will be called `__model__`.

You can load the file named `*__model__.h5` next time if you want to start another training with this one (aka warm start).

Or you can load the trained model for testing new images.

## Testing/Inferencing
Place your files with all the input channels in a folder `test` and you will be able to run prediction on them.

By clicking `test` in the plugin menu, you will start the prediction.

Once done, the result will be saved automatically into the testing folder.
</docs>

<config lang="json">
{
    "name": "U-net",
    "type": "model",
    "tags": ["ImageJ", "CellProfiler", "ImJoy", "Ilastik"],
    "labels": ["PyTorch", "segmentation"],
    "ui": null,
    "version": "0.1.0",
    "api_version": "0.1.0",
    "description": "A U-net model for image segmentation",
    "icon": "extension",
    "inputs": null,
    "outputs": null,
    "requirements": [
    ],
    "cover": [],
    "uri": "repository/unet/unet.model.html"
}
</config>

<script tag="Ilastik;ImJoy;CellProfiler" lang="python">
from ilastik.bioimage import api

class Main():
    def run(self):
        img_in = api.getCurrentImage()
        model = api.loadModel('https://.../model.pb')
        img_out = model.predict(img_in)
        api.showImage(img_in)

api.export(Main())
</script>

<script tag="ImageJ" lang="groovy">
import bioimage.api

class Main {
    def run() {
        ip_in = api.getCurrentImage()
        model = api.loadModel("https://.../model.pb")
        ip_out = model.predict(ip_in)
        api.showImage(ip_out)
    }
}
api.export(new Main())
</script>